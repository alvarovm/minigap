{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***  \n",
    "<h1><center>\n",
    "    miniGAP\n",
    "</center></h1>    \n",
    "\n",
    "***  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform all the functions of miniGAP within this notebook or you can create a python script from the last cell of this notebook and run the script in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization Tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This cell gives us a couple options for debugging Tensorflow.\n",
    "# It is the first code cell, because it must be run, before the TensorFlow library is imported and it is most convenient to import all modules in the next cell\n",
    "# To enable this debugging, you must change one of the debugging flags to True and run this cell *before* importing running later cells\n",
    "# Currently this is only done manually from the notebook, but could be included as a JSON setting in the future if desirable\n",
    "\n",
    "tf_cpu_debugging =False\n",
    "if tf_cpu_debugging:\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    import tensorflow as tf\n",
    "    #tf.debugging.set_log_device_placement(True)\n",
    "    a = tf.constant(1)\n",
    "    \n",
    "    if tf.test.gpu_device_name():\n",
    "        print(\"GPUs recognized by tensorflow:\", tf.config.list_physical_devices('GPU'))\n",
    "    else:\n",
    "        print(\"No GPU found\")\n",
    "\n",
    "tf_gpu_debugging = False\n",
    "if tf_gpu_debugging:\n",
    "#     See here for possible option to reset memory github.com/tensorflow/tensorflow/issues/36465\n",
    "#     import os \n",
    "#     os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "    import tensorflow as tf\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    a = tf.constant(1)\n",
    "    if tf.test.gpu_device_name():\n",
    "        print(\"GPUs recognized by tensorflow:\", tf.config.list_physical_devices('GPU'))\n",
    "    else:\n",
    "        print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell performs a couple initialization tasks that have to start before even importing all the libraries or settings\n",
    "# 1) Determines whether this is being run as a notebook or a script with in_notebook(). Some tasks are only performed in the notebook and vice versa.\n",
    "#    in_notebook() is a function that returns True if this code is run from an ipython kernel or False otherwise\n",
    "#    I need to do this first, because the following task is performed conditional on this being run as a script\n",
    "# 2) Times the initial setup of miniGAP if we are running the miniGAP script.\n",
    "#    Initial setup refers to everything starting with this task up to and including compiling the structure dataset\n",
    "# 3) Import functions and libraries used by miniGAP \n",
    "# 4) Determines a path to the miniGAP home directory which can be used for reading or writing files.\n",
    "# 5) Determines the date for use in naming output files\n",
    "# 6) Sets a printing format\n",
    "# 7) Compiles some functions as tf.functions\n",
    "# 8) Sets a list of values to be interpreted as Nonetype\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from general_purpose_helper_functions import *\n",
    "# True if run from ipython kernel or False otherwise\n",
    "in_notebook = check_if_in_notebook()\n",
    "\n",
    "# Time initial setup\n",
    "import time\n",
    "if not in_notebook:\n",
    "    TimeBeforeStartUp = time.time()\n",
    "\n",
    "# import functions\n",
    "## import functions from my files\n",
    "from Molecular_Dynamics import generate_md_traj, make_diatomic\n",
    "from miniGAP_helper_functions import *\n",
    "from general_purpose_helper_functions import *\n",
    "\n",
    "## import functions from libraries\n",
    "import os.path as path\n",
    "import argparse\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import datetime as dt \n",
    "import resource\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "from gpflow.utilities import print_summary\n",
    "    \n",
    "# Sets the miniGAP home directory. This assumes the notebook or script is located one directory below the home directory.\n",
    "if in_notebook:\n",
    "    miniGAP_parent_directory = \"../\"\n",
    "else:\n",
    "    miniGAP_parent_directory = path.dirname(path.dirname(path.realpath(__file__))) + \"/\"\n",
    "    \n",
    "# Save date for use in naming output files\n",
    "today = dt.datetime.today()\n",
    "today_string = \"_{:02d}_{:02d}_{:d}\".format(today.month, today.day, today.year)\n",
    "\n",
    "# Sets the printing format of gpflow model hyperparameters\n",
    "if in_notebook:\n",
    "    gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "else:\n",
    "    gpflow.config.set_default_summary_fmt(\"grid\")\n",
    "    \n",
    "# Compiles some functions as TensorFlow tf functions not all of which are currently used\n",
    "# Compiled tf functions are several times faster than normal functions\n",
    "mse_tf = tf.function(mse, autograph=False, jit_compile=False)\n",
    "mse_2factor_tf = tf.function(mse_2factor, autograph=False, jit_compile=False)\n",
    "train_hyperparams_without_forces_tf = tf.function(train_hyperparams_without_forces, autograph=False, jit_compile=False)\n",
    "predict_energies_from_weights_tf = tf.function(predict_energies_from_weights, autograph=False, jit_compile=False)\n",
    "\n",
    "# This could be used to define what input values will be interpretted as None.\n",
    "# This may be useful if there are common user-input mistakes when setting a value to None from the commandline or JSON input.\n",
    "# However, I do not use this yet.\n",
    "nonetypes = [None, \"None\", \"null\", \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some input parameter notes (not comprehensive):\n",
    "\n",
    "energy_encoding= \"info\" for QM9 or \"normal\" for distorted propenols  \n",
    "energy_keyword=\"U0\" for QM9 or ignored for distorted propenols\n",
    "\n",
    "my_priority = #\"efficiency\" for experimenting with something new or otherwise \"consistency\"\n",
    "\n",
    "controls initial train_test_split breaking apart training and test data  \n",
    "split_seed = 2\n",
    "\n",
    "controls in-training train_test_split breaking apart training_j and validation_j data  \n",
    "valid_split_seed = 2\n",
    "\n",
    "controls multiple tf stochastic processes including:  \n",
    "1) Adams optimizer AND   \n",
    "2) batching through tf.data.Dataset.from_tensor_slices in training  \n",
    "tf_seed = 2\n",
    "\n",
    "controls batching through tf.data.Dataset.from_tensor_slices in training  \n",
    "shuffle_seed = 2\n",
    "\n",
    "kernel_type = #\"polynomial\" for actual GAP or \"exponentiated_quadratic\" possibly for debugging  \n",
    "\n",
    "prediction_calculation = #\"direct\" OR \"predict_f\" OR \"cholesky\" OR \"alpha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports settings from the JSON file and saves them to JSON_settings_dict \n",
    "# Some settings of JSON_settings_dict may be overwritten by commandline args, but the JSON_settings_dict variable is not edited.\n",
    "# It is unused now, but might be useful for debugging.\n",
    "# Note 1: You can change the input parameters in the JSON file and rerun the notebook starting from here\n",
    "# Note 2: To debug or reformat the JSON file, I recommend jsonformatter.org\n",
    "# Note 3: The settings file from which these data are imported has a nested structure. This is exclusively for ease of navigation for the user.\n",
    "#         The parent settings names such as \"debugging_settings\" are completely ignored by the code\n",
    "#         Therefore, you can also use a settings file saved from a previous run, which may not have a nested structure.\n",
    "\n",
    "settings_json_filename = miniGAP_parent_directory + \"code/miniGAP_settings.json\"\n",
    "with open(settings_json_filename, encoding = 'utf-8') as settings_file_object:\n",
    "    JSON_settings_dict_nested = json.load(settings_file_object)\n",
    "JSON_settings_dict = flatten_dict(JSON_settings_dict_nested)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell allows the miniGAP script to accept commandline parameters\n",
    "# These commandline parameters have priority over the JSON settings\n",
    "# Most, but not all of the JSON settings can be overwritten using a commandline option\n",
    "\n",
    "if not in_notebook:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # arguments for debugging\n",
    "    parser.add_argument('--verbose', type=bool, help=\"Print out details at each step\") \n",
    "    parser.add_argument('-vt', '--print_timings', type=bool, help=\"Print out details at each step\") \n",
    "\n",
    "    # arguments specific to forming dataset (including potentially creating md trajectory)\n",
    "    parser.add_argument('-sf', '--structure_file', help=\"Specify a structure file to import. 'None' will be interpretted as using no structure file.\")\n",
    "    parser.add_argument('-cf', '--chemical_formula',  help=\"If no structure file is supplied, you can specify a single structure here and perform md \\\n",
    "    to generate a trajectory that you will use as your dataset. If neither this nor a structure file are supplied, we will use diatomics.\")\n",
    "    parser.add_argument(\"-md\", '--molecular_dynamics', type=bool, help=\"Indicate if you want molecular dynamics performed. Will generate diatomic if no structure given\")\n",
    "    # available as a JSON parameter, but commandline argument is buggy\n",
    "#     parser.add_argument('-mdi', '--md_indices', default=[0], type=int, nargs='*', help=\"If performing molecular dynamics on a structure file with multiple structures, you can give indices of all structures to perform md on.\")\n",
    "    parser.add_argument('-mdi', '--md_index', type=int, help=\"If performing molecular dynamics on a structure file with multiple structures, you can give the index of the structure to perform md on.\")\n",
    "    parser.add_argument('-de', '--diatomic_element',  choices = [\"N\", \"O\", \"H\"], help=\"If generating diatomics, you can specify element\")\n",
    "    parser.add_argument('-dbl', '--diatomic_bond_length',  type=float, help=\"If generating diatomics, you can specify initial bond length\")\n",
    "    parser.add_argument('-mdt', '--md_temp',  type=float, help=\"If performing molecular dynamics, specify temperatutre (K) of MD\")\n",
    "    parser.add_argument('-mda', '--md_algorithm',  choices = [\"VelocityVerlet\", \"Berendsen\"], type=str, help=\"If performing molecular dynamics, specify algorithm of MD\")\n",
    "    parser.add_argument('-mts', '--md_time_step',  type=float, help=\"If performing molecular dynamics, specify time step (fs) of MD\")\n",
    "    parser.add_argument('-mds', '--md_seed',  type=int, help=\"If performing molecular dynamics, change this seed to get different trajectories\")\n",
    "    parser.add_argument('-mec', '--md_energy_calculator',  choices = [\"EMT\", \"LJ\", \"Morse\"], help = \"If performing molecular dynamics, specify ASE energy/force calculator\")\n",
    "    parser.add_argument('-n', '--n_structs',  type=int, help=\"Specify # of md generated structures or # of structures to use from input file\")\n",
    "\n",
    "    # arguments specific to soap\n",
    "    parser.add_argument('--rcut',  type=float, help= \"Choice of SOAP cut off radius\")\n",
    "    parser.add_argument('--nmax',  type=int, help=\"Choice of SOAP n_max\")\n",
    "    parser.add_argument('--lmax',  type=int, help=\"Choice of SOAP l_max\")\n",
    "\n",
    "    # arguments specific to learning\n",
    "    parser.add_argument('-ss', '--split_seed', type=int, help=\"Random seed for cross-validation\")\n",
    "    parser.add_argument('-tf', '--train_fraction', type=float, help=\"Specify the fraction of structures used in training\")\n",
    "    parser.add_argument('-ne', '--n_epochs', type=int, help=\"Number of epochs\")\n",
    "\n",
    "#     some housekeeping\n",
    "#     parser.add_argument('remainder', nargs=argparse.REMAINDER, help=argparse.SUPPRESS)\n",
    "\n",
    "    cmdline_args = parser.parse_args()\n",
    "    cmdline_args_dict = vars(cmdline_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a namedtuple variable, 's', which stores all settings. For details on how to use a namedtuple, see next cell.\n",
    "# If this is run as a script then, prior to creating s, we check if there are commandline arguments.\n",
    "# Any commandline argument overwrites the default argument from the JSON settings file in the dictionary 'settings_dict'\n",
    "# The settings from the JSON file are used whenever no commandline argument exists.\n",
    "\n",
    "settings_dict = JSON_settings_dict.copy()\n",
    "# Synchronize the JSON and commandline settings\n",
    "if not in_notebook:\n",
    "    for setting_name in settings_dict.keys():\n",
    "        if setting_name in cmdline_args_dict.keys():\n",
    "            if cmdline_args_dict[setting_name] != None:\n",
    "                settings_dict[setting_name] = cmdline_args_dict[setting_name]\n",
    "    \n",
    "    for setting_name in cmdline_args_dict.keys():\n",
    "        if setting_name not in settings_dict.keys():\n",
    "            print(\"The commandline argument {} is currently nonfunctional because it does not exist in the JSON file.\".format(setting_name))\n",
    "\n",
    "# Created the namedtuple variable storing all the settings\n",
    "# I name the namedtuple settings object with one letter 's' instead of using 'Settings' to minimize disruption of the code\n",
    "# However, you may need for the variable name and the string assigned to 'typename' to be the same if you are pickling.\n",
    "# 'typename' is the first parameter of namedtuple() and was 'Settings' when I wrote this comment\n",
    "SettingsNamespace = namedtuple(\"Settings\", settings_dict.keys())\n",
    "s = SettingsNamespace(*settings_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the flag to True to see a demonstration of how to use a namedtuple variable\n",
    "\n",
    "demonstrate_named_tuple=False\n",
    "\n",
    "if demonstrate_named_tuple:\n",
    "    # You can iterate through the elements of a named_tuple\n",
    "    # s._fields contains the setting names or fields\n",
    "    n_settings_to_print = 10\n",
    "    print(\"The first {} fields and values within s:\".format(n_settings_to_print) )\n",
    "    for setting_field, setting_value in zip(s._fields[:n_settings_to_print], s[:n_settings_to_print]):\n",
    "        print(\"\\t{} = {}\".format(setting_field, setting_value))\n",
    "    print(\"\\t...\\n\")\n",
    "    \n",
    "    # You can acccess variables of a named tuple in 2 ways\n",
    "    print(\"2 ways of accessing values stored in s:\")\n",
    "    # 1) As an attribute\n",
    "    print(\"\\t1) s.structure_file = {}\".format(s.structure_file) )\n",
    "    \n",
    "    # 2) Indexing\n",
    "    index_for_demonstration = [i for i in range(len(s._fields)) if s._fields[i] == \"structure_file\"][0]\n",
    "    print(\"\\t2) s[{}] = {}\".format(index_for_demonstration, s[index_for_demonstration]))\n",
    "\n",
    "    # I exclusively use this method in miniGAP code because this allows me to just prepend 's.' to any variable I had been using \n",
    "    #     from my previous code, which defined all variables within a notebook and had no JSON or commandline arg input.\n",
    "    # Another convenience of using a namedtuple is that I can just replace 's.' with 'self.' in the futurewhen when I convert \n",
    "    #     the majority of miniGAP code into a GAP class.\n",
    "\n",
    "# For more details see docs.python.org/3/library/collections.html#collections.namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell allows for saving results if run from a script\n",
    "# If the user so chooses:\n",
    "#     1) A new subdirectory will be created for the results output files\n",
    "#            The new subdirectory is /minigap/results/CALCULATIONTITLE where CALCULATIONTITLE is determined by user input and existing directories\n",
    "#     2) All output (stdout) printed to terminal is also saved to a file in CALCULATIONTITLE\n",
    "#     3) The settings are saved to a file in CALCULATIONTITLE similar to the JSON input file\n",
    "\n",
    "\n",
    "if s.make_output_files and not in_notebook:\n",
    "    # Make new subdirectory\n",
    "    # The name can be given by s.title or it will just be 'results'\n",
    "    # If s.append_date_to_title is set to True, the date will be added to the end\n",
    "    # If a directory already exists with the attempted name, the lowest possible integer to make a unique name is added to the end\n",
    "    calculation_results_directory = make_miniGAP_results_subdirectory(s, date=today_string, miniGAP_parent_directory=miniGAP_parent_directory)\n",
    "    \n",
    "    # Start saving output to a log file as well as printing it to the terminal\n",
    "    log_filename = calculation_results_directory + \"/miniGAP.log\"\n",
    "    logger = Logger(log_filename)\n",
    "    if s.verbose:\n",
    "        print(\"Logging all output starting now into {}\".format(log_filename))\n",
    "    \n",
    "    # Save settings used for this calculation for future reference\n",
    "    output_JSON_filename = calculation_results_directory + \"/miniGAP.settings\"    \n",
    "    with open(output_JSON_filename, 'w', encoding='utf-8') as settings_output_file:\n",
    "        json.dump(settings_dict, settings_output_file, ensure_ascii=False, indent=4)\n",
    "    if s.verbose:\n",
    "        print(\"Input settings for this calculation stored in {}\".format(output_JSON_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization Tasks (continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack size set to unlimited\n",
      "1 GPU(s) recognized by tensorflow: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# This cell handles initialization tasks which could not be completed previously.\n",
    "# These tasks potentially print out some output depending on the s.verbose setting so they could not be performed\n",
    "#     1) prior to importing the settings, or\n",
    "#     2) prior to initiating the logging (or else the outputs would not be logged.) \n",
    "\n",
    "# miniGAP uses a lot memory so it is good to allow it access to as much as possible\n",
    "try:\n",
    "    resource.setrlimit( resource.RLIMIT_STACK, ( resource.RLIM_INFINITY, resource.RLIM_INFINITY ) )\n",
    "    if s.verbose:\n",
    "        print(\"Stack size set to unlimited\")\n",
    "except:\n",
    "    print(\"Warning: Unable to raise stack size limit. Typically miniGAP uses a lot of memory and operates better if you allow the stack size to be unlimited. You can try to do this with the command 'ulimit -s unlimited'\")\n",
    "\n",
    "# Check on GPU availability\n",
    "if s.verbose:\n",
    "    print(\"{} GPU(s) recognized by tensorflow:\".format(len(tf.config.list_physical_devices('GPU'))), tf.config.list_physical_devices('GPU'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 1000 structures from ../data/distorted_propenol.db. Structures were taken uniformly from throughout dataset which contains 2000 total structures.\n",
      "Compiling structures into list took 0.85 seconds\n"
     ]
    }
   ],
   "source": [
    "# This cell compiles the structure dataset to be used by miniGAP\n",
    "# You have several options for how to choosing this dataset:\n",
    "# 1) Import structure dataset directly from file\n",
    "# 2) Import a structure from a file and then run an MD simulation with ASE. \n",
    "#    The structures in the MD trajectory will be used as the dataset.\n",
    "# 3) Do not use a file ('\"structure_file\" : null' in the JSON). Specify the chemical formula of a molecule within the g2 collection and then run an MD simulation with ASE.\n",
    "#    The structures in the MD trajectory will be used as the dataset.\n",
    "#    Information about the g2 collection:\n",
    "#      - https://aip.scitation.org/doi/10.1063/1.473182\n",
    "#      - https://wiki.fysik.dtu.dk/ase/ase/build/build.html#molecules\n",
    "# 4) Do not use a file or specify a chemical formula('\"structure_file\" : null'  and '\"chemical_formula\" : null' in the JSON).\n",
    "#    This is like option 3, but the starter molecule will be a diatomic.\n",
    "#    You can specify the diatomic element and initial bond length in the JSON or commandline arguments.\n",
    "\n",
    "# Note 1: If you don't include a path in the filename, miniGAP will look in the /minigap/data/ directory \n",
    "# Note 2: Currently only the force fields with a native ASE implementation are implemented for MD generation of a dataset.\n",
    "#         These forcfield are \"EMT\", \"LJ\", and \"Morse\". All perform very poorly for nearly all molecules and structures.\n",
    "#         An exception is diatomic molecules, for which they capture the most important behavior.\n",
    "# Note 3: You can see here that I use the function 'TickTock'. The real function is 'CompileStructureList'.\n",
    "#         'TickTock' is is just for timing purposes. See the next cell for more details.\n",
    "\n",
    "StructureList, TimeCompileStructures = TickTock(CompileStructureList, s, in_notebook, miniGAP_parent_directory)\n",
    "if s.print_timings:\n",
    "    print(\"Compiling structures into list took {:.2f} seconds\".format(TimeCompileStructures))\n",
    "\n",
    "\n",
    "ns_atoms = np.unique([len(struct) for struct in StructureList])\n",
    "assert len(ns_atoms) == 1\n",
    "n_atoms = ns_atoms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will see the TickTock function used throughout this notebook\n",
    "# It is a helper function that allows me to time other functions concisely.\n",
    "# For an example usage set the below flag to True and inspect the code\n",
    "\n",
    "see_example_of_TickTock_usage = False\n",
    "if see_example_of_TickTock_usage:\n",
    "    def example_function(a, b, c=\"DEFAULT_VALUE\", d=\"DEFAULT_VALUE\", function_call_type=\"normal\"):\n",
    "        summation=0\n",
    "        for i in range(a):\n",
    "            summation += b\n",
    "        print(\"This {} function call accepted the argument '{}' for the positional parameter 'a'\".format(function_call_type, a))\n",
    "        print(\"This {} function call accepted the argument '{}' for the positional parameter 'b'\".format(function_call_type, b))\n",
    "        print(\"This {} function call accepted the argument '{}' for the keyword parameter 'c'\".format(function_call_type, c))\n",
    "        print(\"This {} function call accepted the argument '{}' for the keyword parameter 'd'\".format(function_call_type, d))\n",
    "        return summation\n",
    "    \n",
    "    a_value = 1234567\n",
    "    b_value = 1\n",
    "    c_value = \"CAT\"\n",
    "    d_value = \"DOG\"\n",
    "    \n",
    "    # You can use the function the normal way:\n",
    "    normal_function_output = example_function(a_value, b_value, c=c_value, d=d_value, function_call_type=\"normal\")\n",
    "    print(\"This normal function call returned {}\\n\".format(normal_function_output) )\n",
    "    \n",
    "    # You can time the function with a slight modification, no extra lines needed\n",
    "    TickTock_function_output, function_time = TickTock(example_function, a_value, b_value, c=c_value, d=d_value, function_call_type=\"TickTock\")\n",
    "    print(\"This TickTock function call returned {}\".format(TickTock_function_output) )\n",
    "    print(\"This TickTock function call took {:.2f} seconds to run\".format(function_time) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set convert flag to True and run this cell to convert your file to a database right now from this notebook\n",
    "# I do not recommend this. The database creation is very slow and will lock you out from running any cells for a long time.\n",
    "# It is better to do this from a terminal with the script convert_to_db.py\n",
    "# For example, you can run the command '/relative/path/to/minigap/code/convert_to_db.py structure_file_a.xyz structure_file_b.xyz structure_file_c.xyz'\n",
    "# This command would create the files structure_file_a.db, structure_file_b.db and structure_file_c.db in your /relative/path/to/minigap/data/ directory\n",
    "# To overwrite an existing .db file use the --existing_file_behavior flag\n",
    "# convert_to_db.py --help will explain some more details\n",
    "convert_to_db_here_and_now = False\n",
    "if convert_to_db_here_and_now and in_notebook:\n",
    "    !python ../code/convert_to_db.py $s.structure_file \n",
    "    # Use the following line instead of the previous line if you need to overwrite an existing database\n",
    "    # !python ../code/convert_to_db.py -efb overwrite $s.structure_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell completes the timing started in the first cell if this code is executed from a script\n",
    "\n",
    "if s.print_timings and not in_notebook:\n",
    "    TimeAfterStartUp = time.time()\n",
    "    TimeStartUp = TimeAfterStartUp - TimeBeforeStartUp\n",
    "    print(\"Completed the initial setup of miniGAP (including importing structures) in {:.2f} seconds\".format(TimeStartUp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to True if you want to visualize your structure within this jupyter notebook (no pop-up window)\n",
    "# For more details on the plotting function, refer to the Visualize_Structures notebook\n",
    "\n",
    "check_structures_visually = False\n",
    "if check_structures_visually:\n",
    "    from Visualize_Structures import Structure3DAnimation\n",
    "    # You can display the animation in one line if you are not within an if statement.\n",
    "    # But you need to explicitly call display() if you are within an if statement:\n",
    "    # 'Structure3DAnimation(StructureList).Plot()'\n",
    "    html_animation = Structure3DAnimation(StructureList).Plot()\n",
    "    display(html_animation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered energy and structure info in 2.33 seconds\n"
     ]
    }
   ],
   "source": [
    "# This cell \n",
    "\n",
    "[EnergyList, ForceList, PosList], TimeGather = TickTock(GatherStructureInfo, StructureList, gather_forces = s.use_forces, use_self_energies=s.use_self_energies, \n",
    "                                                     energy_encoding = s.energy_encoding,  energy_keyword = s.energy_keyword)\n",
    "gather_forces_message= \", force\" if s.use_forces else \"\"\n",
    "if s.print_timings:\n",
    "    print(\"Gathered energy{} and structure info in {:.2f} seconds\".format(gather_forces_message, TimeGather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SOAP descriptors in 1.18 seconds\n"
     ]
    }
   ],
   "source": [
    "[SoapDerivativeList, SoapList], TimeSoap = TickTock(GenerateDescriptorsAndDerivatives, StructureList, s.nmax, s.lmax, s.rcut, s.smear, s.attach_SOAP_center, s.is_periodic, s.use_forces)\n",
    "calculate_derivatives_message = \" and derivatives\" if s.use_forces else \"\"\n",
    "if s.print_timings:\n",
    "    print(\"Generated SOAP descriptors{} in {:.2f} seconds\".format(calculate_derivatives_message, TimeSoap))\n",
    "elif s.verbose:\n",
    "    print(\"Generated SOAP descriptors{}.\".format(calculate_derivatives_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformatted data to build model in 0.33 seconds.\n"
     ]
    }
   ],
   "source": [
    "out_data, TimePrepare = TickTock(PrepareDataForTraining, \n",
    "                                sp_list=SoapList, \n",
    "                                dsp_dx_list = SoapDerivativeList, \n",
    "                                en_list = EnergyList,\n",
    "                                frc_list = ForceList ,\n",
    "                                pos_list = PosList, \n",
    "                                split_seed = s.split_seed, \n",
    "                                prepare_forces = s.use_forces, \n",
    "                                train_fract = s.train_fraction,\n",
    "                                scale_soaps = s.scale_soaps\n",
    "                                )\n",
    "\n",
    "if s.print_timings:\n",
    "    print(\"Reformatted data to build model in {:.2f} seconds.\".format(TimePrepare))\n",
    "\n",
    "if not s.use_forces:\n",
    "    train_sps_full, test_sps_full, train_ens, test_ens, train_indices, test_indices, soap_scaler, ens_scaler, ens_var = out_data\n",
    "else:\n",
    "    train_sps_full, test_sps_full, train_ens, test_ens, train_indices, test_indices, soap_scaler, ens_scaler, ens_var, train_dsp_dx, test_dsp_dx, train_frcs, test_frcs, frcs_var = out_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using any sparsity.\n"
     ]
    }
   ],
   "source": [
    "n_samples_full, n_features_full = train_sps_full.shape\n",
    "SparsifySoapsOutput, TimeSparsify = TickTock( SparsifySoaps, train_soaps = train_sps_full, test_soaps = test_sps_full, train_energies=train_ens, sparsify_samples=s.sparse_gpflow, \n",
    "                                    n_samples=s.n_sparse, sparsify_features=s.sparse_features, n_features=s.n_sparse_features, selection_method=\"PCovCUR\",\n",
    "                                    score_tolerance=1e-5, score_threshold=1e-5, iterative_selection=False, plot_importances=False) \n",
    "train_sps, sparse_train_sps, test_sps = SparsifySoapsOutput\n",
    "if s.sparse_gpflow or s.sparse_features:\n",
    "    sparsity_samples_message = \"\" if not s.sparse_gpflow else \"samples ({} --> {})\".format(n_samples_full, sparse_train_sps.shape[0])\n",
    "    sparsity_features_message = \"\" if not s.sparse_features else \"features ({} --> {})\".format(n_features_full, train_sps.shape[-1])\n",
    "    sparsity_both_message = \" and \" if (s.sparse_gpflow and s.sparse_features) else \"\"\n",
    "    if s.print_timings:\n",
    "        print(\"Sparsified model {}{}{} in {:.2f} seconds.\".format( sparsity_samples_message, sparsity_both_message, sparsity_features_message, TimeSparsify) )\n",
    "    elif s.verbose:\n",
    "        print(\"Sparsified model {}{}{}\".format( sparsity_samples_message, sparsity_both_message, sparsity_features_message) )\n",
    "else:\n",
    "    if s.verbose:\n",
    "        print(\"Not using any sparsity.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future investigations for hyperparameter training\n",
    "---\n",
    "1. Does Adam optimizer have problems sometimes within a tf.function?\n",
    "2. Custom loss function vs optimizer.minimize\n",
    "3. Set certain variable untrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 03:43:17.247719: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-06 03:43:17.795333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9686 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:01:00.0, compute capability: 7.0\n",
      "2021-12-06 03:43:17.934798: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a degree 2 polynomial kernel.\n",
      "Alert: Double check the training validity for degree =/= 1 when not using predict_f\n",
      "Training using 8100 atoms without batching.\n"
     ]
    }
   ],
   "source": [
    "# Initialize kernels and model hyperparameters\n",
    "tf.random.set_seed(s.tf_seed)\n",
    "\n",
    "TimeBeforePreEpoch = time.time()\n",
    "\n",
    "\n",
    "noise_init = 1e-4 #.001# 0.0005499093576274776 #1.625e-4\n",
    "obs_noise = tf.Variable(noise_init, dtype=s.dtype, name=\"noise\")\n",
    "\n",
    "degree=2\n",
    "kernel = pick_kernel(s.kernel_type, amplitude=1, verbose=s.verbose, degree=degree)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "# Now validation set acts as temporary est set\n",
    "# train_test_split and tensorflow tensors don't get along so I temporarily convert them back to numpy arrays\n",
    "\n",
    "train_indices_j, valid_indices_j  = train_test_split(np.arange(len(train_sps)), random_state = s.valid_split_seed, test_size=(1-s.valid_fract))\n",
    "\n",
    "train_sps_j, valid_sps_j = train_sps[train_indices_j], train_sps[valid_indices_j]\n",
    "train_ens_j, valid_ens_j = train_ens[train_indices_j], train_ens[valid_indices_j]\n",
    "\n",
    "if s.use_forces: \n",
    "    train_dsp_dx_j, valid_dsp_dx_j = train_dsp_dx[train_indices_j], train_dsp_dx[valid_indices_j]\n",
    "    train_frcs_j, valid_frcs_j = train_frcs[train_indices_j], train_frcs[valid_indices_j]\n",
    "\n",
    "# Convert to tensorflow constant tensors\n",
    "# train_sps_j = tf.constant(train_sps_j, dtype=s.dtype)\n",
    "# train_ens_j = tf.constant(train_ens_j, dtype=s.dtype)\n",
    "valid_sps_j = tf.constant(valid_sps_j, dtype=s.dtype)\n",
    "# valid_ens_j = tf.constant(valid_ens_j, dtype=s.dtype)\n",
    "\n",
    "if s.sparse_gpflow:\n",
    "    sparse_train_sps = tf.Variable(sparse_train_sps, shape=sparse_train_sps.shape, dtype=s.dtype, trainable=False)\n",
    "\n",
    "if s.use_forces:\n",
    "    train_dsp_dx_j = tf.constant(train_dsp_dx_j, dtype=s.dtype)\n",
    "    train_frcs_j = tf.constant(train_frcs_j, dtype=s.dtype)    \n",
    "    valid_dsp_dx_j = tf.constant(valid_dsp_dx_j, dtype=s.dtype)\n",
    "    valid_frcs_j = tf.constant(valid_frcs_j, dtype=s.dtype)        \n",
    "\n",
    "test_sps = tf.constant(test_sps, dtype=s.dtype)\n",
    "\n",
    "\n",
    "# Batch data if  training set is larger than batch_size_max\n",
    "if len(train_sps_j) < s.batch_size_max:\n",
    "    iterations_per_epoch = 1\n",
    "    batch_size = len(train_sps_j)\n",
    "    if s.verbose:\n",
    "        print(\"Training using {} atoms without batching.\".format(len(train_sps_j)))\n",
    "else:\n",
    "    iterations_per_epoch = int(np.ceil(len(train_sps_j)/s.batch_size_max))\n",
    "    batch_size = int(np.ceil(len(train_sps_j)/iterations_per_epoch))\n",
    "    if s.verbose:\n",
    "        print(\"Training using {} atoms total using {} batches with {} atoms per batch.\".format( len(train_sps_j), iterations_per_epoch, batch_size ))\n",
    "\n",
    "# training(out_data)\n",
    "        \n",
    "TimeBeforeEpoch0 = time.time()\n",
    "\n",
    "\n",
    "mse_history = []    \n",
    "hyperparam_history = []\n",
    "\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# \n",
    "# from gpflow.models import VGP, GPR, SGPR, SVGP\n",
    "# from gpflow.optimizers import NaturalGradient\n",
    "# from gpflow.optimizers.natgrad import XiSqrtMeanVar\n",
    "# from gpflow import set_trainable\n",
    "\n",
    "\n",
    "if s.my_priority == \"efficiency\":\n",
    "    # I don't know what this does\n",
    "    autotune = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    \n",
    "    batches = (\n",
    "        tf.data.Dataset.from_tensor_slices((train_sps_j, train_ens_j))\n",
    "        .prefetch(autotune) \n",
    "        .shuffle(buffer_size=len(train_sps_j), seed=s.shuffle_seed)\n",
    "        .repeat(count=None)\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    \n",
    "    batch_iterator = iter(batches)\n",
    "\n",
    "    # I also don't know why we use this\n",
    "    from gpflow.ci_utils import ci_niter, ci_range\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=s.learn_rate)\n",
    "    \n",
    "else:\n",
    "    batches = (\n",
    "        tf.data.Dataset.from_tensor_slices((train_sps_j, train_ens_j)) \n",
    "        .shuffle(buffer_size=len(train_sps_j), seed=s.shuffle_seed) \n",
    "        .repeat(count=None)\n",
    "        .batch(batch_size)\n",
    "    )    \n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=s.learn_rate)\n",
    "#     optimizer = tf.keras.optimizers.SGD(learning_rate=s.learn_rate)\n",
    "    \n",
    "train_hyperparams_without_forces_tf = tf.function(train_hyperparams_without_forces, autograph=False, jit_compile=False)\n",
    "\n",
    "# new code to make tf.function training work\n",
    "# --------------------------------------------\n",
    "train_sps_j_i = tf.Variable(train_sps[:batch_size], shape=(batch_size, train_sps.shape[-1]), dtype=s.dtype, trainable=False )\n",
    "train_ens_j_i = tf.Variable(train_ens[:batch_size], shape=(batch_size, 1), dtype=s.dtype, trainable=False ) \n",
    "if s.sparse_gpflow:\n",
    "    if sparse_train_sps.shape[0] >= batch_size:\n",
    "        print(\"Warning: Batch size is not greater than sparse soap size.\\nThis may cause errors in the predict_f function which assumes the inducing points to be fewer than the data points.\")\n",
    "    if s.my_priority == \"efficiency\":\n",
    "        gpr_model = gpflow.models.SVGP( kernel=kernel, likelihood=gpflow.likelihoods.Gaussian(),  inducing_variable=sparse_train_sps)\n",
    "        gpr_model.likelihood.variance.assign(obs_noise)\n",
    "        gpflow.set_trainable(gpr_model.q_mu, False)\n",
    "        gpflow.set_trainable(gpr_model.q_sqrt, False)\n",
    "    else:\n",
    "        gpr_model = gpflow.models.SGPR(data=(train_sps_j_i, train_ens_j_i), kernel=kernel, noise_variance=obs_noise, inducing_variable=sparse_train_sps)\n",
    "else:\n",
    "    if s.my_priority == \"efficiency\":\n",
    "        # it seems I cannot use  noise_variance=obs_noise for this which makes it not GAP...\n",
    "        gpr_model = gpflow.models.VGP( data=(train_sps_j_i, train_ens_j_i), kernel=kernel, likelihood=gpflow.likelihoods.Gaussian())\n",
    "    else:\n",
    "        gpr_model = gpflow.models.GPR( data=(train_sps_j_i, train_ens_j_i), kernel=kernel, noise_variance=obs_noise)\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "print_frequency = max(s.min_print_frequency, int(s.n_epochs/10))\n",
    "\n",
    "if s.my_priority == \"efficiency\":\n",
    "    hyperparam_history.append([(0, np.exp(var.numpy() )) for var in gpr_model.trainable_variables])  \n",
    "    gpr_objective = gpr_model.training_loss_closure(batch_iterator,  compile=True)\n",
    "    for j in range(ci_niter(s.n_epochs)):\n",
    "        if not j % print_frequency:\n",
    "            print(\"Epoch {}\".format(j))\n",
    "        optimizer.minimize(gpr_objective, var_list=gpr_model.trainable_variables)\n",
    "        mse_history.append((j+1, gpr_model.elbo(data=(train_sps, train_ens))))\n",
    "        hyperparam_history.append([(j+1, np.exp(var.numpy()) ) for var in gpr_model.trainable_variables]) \n",
    "    #optimizer.minimize(gpr_model.training_loss, gpr_model.trainable_variables, options=dict(maxiter=s.n_epochs))\n",
    "        \n",
    "elif s.my_priority == \"consistency\":\n",
    "\n",
    "    hyperparam_history.append([(0, var.numpy()) for var in gpr_model.trainable_parameters])  \n",
    "    for j in range(s.n_epochs):\n",
    "        if not j % print_frequency:\n",
    "            print(\"Epoch {}\".format(j))\n",
    "            #print(\" \".join([\"{} = {:.2e} \".format(var.name, np.exp(var.numpy())) for var in trainable_variables]))\n",
    "\n",
    "        mse_ens_j = 0\n",
    "        for i, (train_sps_j_i, train_ens_j_i) in enumerate(islice(batches, iterations_per_epoch)):\n",
    "            if not s.use_forces: #and not s.sparse_gpflow :\n",
    "                gpr_model.data[0].assign(train_sps_j_i)\n",
    "                gpr_model.data[1].assign(train_ens_j_i)        \n",
    "                mse_ens_j_i = train_hyperparams_without_forces_tf(gpr_model, valid_sps_j, valid_ens_j, optimizer)\n",
    "                print(\"valid_ens[:3] = {}\".format( valid_ens_j[:3].flatten()) )\n",
    "#                 print(mse_ens_j_i.numpy(), valid_ens_j[:3].numpy().flatten(), train_ens_j_i[:3].numpy().flatten()  )\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(\"Using older approach (not converted to tf.function yet)\")\n",
    "                with tf.GradientTape() as tape:\n",
    "                    with tf.GradientTape(watch_accessed_variables=False) as tape_sps:\n",
    "                        tape_sps.watch(valid_sps_j)\n",
    "                        if s.sparse_gpflow:\n",
    "                            gpr_model = gpflow.models.SGPR(data=(train_sps_j_i, train_ens_j_i), kernel=kernel, inducing_variable=sparse_train_sps)\n",
    "    #                         gpflow.set_trainable(gpr_model.inducing_variable, False)\n",
    "                            if i < 3:\n",
    "                                print_summary(gpr_model)            \n",
    "                        else:\n",
    "                            gpr_model.data[0].assign(train_sps_j_i)\n",
    "                            gpr_model.data[1].assign(train_ens_j_i)\n",
    "                            #gpr_model = gpflow.models.GPR(data=(train_sps_j_i, train_ens_j_i), kernel=kernel)\n",
    "                        #gpr_model.likelihood.variance.assign(obs_noise)                \n",
    "                        predict_ens_j_i = gpr_model.predict_f(valid_sps_j)[0]\n",
    "\n",
    "        #                 gpr_model = gpflow.models.GPR(data=(sps_j_i, train_ens_j_i), kernel=kernel_gpf)\n",
    "        #                 gpr_model.likelihood.variance.assign(obs_noise_gpf)\n",
    "        #                 predict_ens_j_i_gpf = gpr_model.predict_f(valid_sps_j)\n",
    "\n",
    "                    if s.use_forces:\n",
    "                        predict_d_ens_j_i = tape_sps.gradient(predict_ens_j_i, valid_sps_j)\n",
    "                        # In the following line I needed to include '* n_atoms' after breaking energies into local energies\n",
    "                        # The reason is that I am effectively breaking the connection between E and F when doing that\n",
    "                        # F = -dE/dx =/= -dE_local/dx where E_local = E/n_atoms - E_free\n",
    "                        # When I split energies into local energies I initially calculated -dE_local/dx which is -dE/dx / n_atoms\n",
    "                        # This fix is prone to breaking the code and is not robust to systems with different structure size\n",
    "                        # Need to improve this with a better fix\n",
    "                        predict_frcs_j_i = -1*np.einsum('ijk,ik->ij', valid_dsp_dx_j, predict_d_ens_j_i) * n_atoms\n",
    "                        mse_j_i = mse_2factor_tf(predict_ens_j_i, valid_ens_j, 1/ens_var,\n",
    "                                                predict_frcs_j_i, valid_frcs_j, 1/frcs_var)\n",
    "                        mse_ens_j_i = mse_tf(predict_ens_j_i, valid_ens_j)\n",
    "                    else:\n",
    "                        mse_j_i = mse_tf(predict_ens_j_i, valid_ens_j)\n",
    "                        mse_ens_j_i = mse_j_i\n",
    "\n",
    "\n",
    "        #         grads = tape.gradient(mse_j_i, trainable_variables)\n",
    "        #         optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "                grads = tape.gradient(mse_j_i, gpr_model.trainable_variables)\n",
    "                # print(gpr_model.trainable_variables[0])#grads[0])\n",
    "                optimizer.apply_gradients(zip(grads, gpr_model.trainable_variables))\n",
    "                if i < 3:\n",
    "                    print_summary(gpr_model)\n",
    "\n",
    "                if not gpr_model.data[0][0,0].numpy() == train_sps_j_i[0,0].numpy() :\n",
    "                    print(\"ERRORERRORERRORERRORERRORERRORERROR\")\n",
    "\n",
    "            print(\"Adding mse_ens_j_i to mse_ens_j: {} + {} = {} \".format(mse_ens_j_i.numpy(), mse_ens_j , mse_ens_j_i.numpy() + mse_ens_j  ))\n",
    "            mse_ens_j += mse_ens_j_i\n",
    "\n",
    "        mse_ens_j /= iterations_per_epoch\n",
    "        print(\"Epoch {},  mse = {}\".format(j, mse_ens_j))\n",
    "        mse_history.append((j+1, mse_ens_j))\n",
    "        hyperparam_history.append([(j+1, var.numpy()) for var in gpr_model.trainable_parameters])    \n",
    "else:\n",
    "    print(\"{} is not a reconized value for my_priority.\\n Training did not occur.\".format(s.my_priority))\n",
    "\n",
    "\n",
    "\n",
    "TimeBeforeWeights = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am currently (11/30) converting the hyperparameter learning in this cell into a function\n",
    "# Next will be the post-hyperparameter part of the learning (in the next cell)\n",
    "\n",
    "# # Initialize kernels and model hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "# def train_hyperparams(train_sps, train_ens, sparse_train_sps, kernel, settings):\n",
    "#     tf.random.set_seed(settings.tf_seed)\n",
    "\n",
    "\n",
    "#     noise_init = 1e-4 #.001# 0.0005499093576274776 #1.625e-4\n",
    "#     obs_noise = tf.Variable(noise_init, dtype=settings.dtype, name=\"noise\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Split training data into training and validation sets\n",
    "#     # Now validation set acts as temporary est set\n",
    "#     # train_test_split and tensorflow tensors don't get along so I temporarily convert them back to numpy arrays\n",
    "\n",
    "#     train_indices_j, valid_indices_j  = train_test_split(np.arange(len(train_sps)), random_state = settings.valid_split_seed, test_size=(1-settings.valid_fract))\n",
    "\n",
    "#     train_sps_j, valid_sps_j = train_sps[train_indices_j], train_sps[valid_indices_j]\n",
    "#     train_ens_j, valid_ens_j = train_ens[train_indices_j], train_ens[valid_indices_j]\n",
    "\n",
    "#     if settings.use_forces: \n",
    "#         train_dsp_dx_j, valid_dsp_dx_j = train_dsp_dx[train_indices_j], train_dsp_dx[valid_indices_j]\n",
    "#         train_frcs_j, valid_frcs_j = train_frcs[train_indices_j], train_frcs[valid_indices_j]\n",
    "\n",
    "#     # Convert to tensorflow constant tensors\n",
    "#     train_sps_j = tf.constant(train_sps_j, dtype=settings.dtype)\n",
    "#     train_ens_j = tf.constant(train_ens_j, dtype=settings.dtype)\n",
    "#     valid_sps_j = tf.constant(valid_sps_j, dtype=settings.dtype)\n",
    "#     valid_ens_j = tf.constant(valid_ens_j, dtype=settings.dtype)\n",
    "#     if settings.sparse_gpflow:\n",
    "#         sparse_train_sps = tf.Variable(sparse_train_sps, shape=sparse_train_spsettings.shape, dtype=settings.dtype, trainable=False)\n",
    "\n",
    "#     if settings.use_forces:\n",
    "#         train_dsp_dx_j = tf.constant(train_dsp_dx_j, dtype=settings.dtype)\n",
    "#         train_frcs_j = tf.constant(train_frcs_j, dtype=settings.dtype)    \n",
    "#         valid_dsp_dx_j = tf.constant(valid_dsp_dx_j, dtype=settings.dtype)\n",
    "#         valid_frcs_j = tf.constant(valid_frcs_j, dtype=settings.dtype)        \n",
    "\n",
    "#     test_sps = tf.constant(test_sps, dtype=settings.dtype)\n",
    "\n",
    "\n",
    "#     # Batch data if  training set is larger than batch_size_max\n",
    "#     if len(train_sps_j) < settings.batch_size_max:\n",
    "#         iterations_per_epoch = 1\n",
    "#         batch_size = len(train_sps_j)\n",
    "#         if s.verbose:\n",
    "#             print(\"Training using {} atoms without batching.\".format(len(train_sps_j)))\n",
    "#     else:\n",
    "#         iterations_per_epoch = int(np.ceil(len(train_sps_j)/settings.batch_size_max))\n",
    "#         batch_size = int(np.ceil(len(train_sps_j)/iterations_per_epoch))\n",
    "#         if s.verbose:\n",
    "#             print(\"Training using {} atoms total using {} batches with {} atoms per batch.\".format( len(train_sps_j), iterations_per_epoch, batch_size ))\n",
    "\n",
    "#     # training(out_data)\n",
    "\n",
    "#     TimeBeforeEpoch0 = time.time()\n",
    "\n",
    "\n",
    "#     mse_history = []    \n",
    "#     hyperparam_history = []\n",
    "\n",
    "\n",
    "\n",
    "#     # import warnings\n",
    "#     # \n",
    "#     # from gpflow.models import VGP, GPR, SGPR, SVGP\n",
    "#     # from gpflow.optimizers import NaturalGradient\n",
    "#     # from gpflow.optimizers.natgrad import XiSqrtMeanVar\n",
    "#     # from gpflow import set_trainable\n",
    "\n",
    "\n",
    "#     if settings.my_priority == \"efficiency\":\n",
    "#         # I don't know what this does\n",
    "#         autotune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "#         batches = (\n",
    "#             tf.data.Dataset.from_tensor_slices((train_sps_j, train_ens_j))\n",
    "#             .prefetch(autotune) \n",
    "#             .shuffle(buffer_size=len(train_sps_j), seed=settings.shuffle_seed)\n",
    "#             .repeat(count=None)\n",
    "#             .batch(batch_size)\n",
    "#         )\n",
    "\n",
    "#         batch_iterator = iter(batches)\n",
    "\n",
    "#         # I also don't know why we use this\n",
    "#         from gpflow.ci_utils import ci_niter, ci_range\n",
    "\n",
    "#         optimizer = tf.keras.optimizers.Adam(learning_rate=settings.learn_rate)\n",
    "\n",
    "#     else:\n",
    "#         batches = (\n",
    "#             tf.data.Dataset.from_tensor_slices((train_sps_j, train_ens_j)) \n",
    "#             .shuffle(buffer_size=len(train_sps_j), seed=settings.shuffle_seed) \n",
    "#             .repeat(count=None)\n",
    "#             .batch(batch_size)\n",
    "#         )    \n",
    "\n",
    "#         optimizer = tf.keras.optimizers.Adam(learning_rate=settings.learn_rate)\n",
    "#         #optimizer = tf.keras.optimizers.SGD(learning_rate=settings.learn_rate)\n",
    "\n",
    "\n",
    "\n",
    "#     # new code to make tf.function training work\n",
    "#     # --------------------------------------------\n",
    "#     train_sps_j_i = tf.Variable(train_sps[:batch_size], shape=(batch_size, train_sps.shape[-1]), dtype=settings.dtype, trainable=False )\n",
    "#     train_ens_j_i = tf.Variable(train_ens[:batch_size], shape=(batch_size, 1), dtype=settings.dtype, trainable=False ) \n",
    "#     if settings.sparse_gpflow:\n",
    "#         if sparse_train_sps.shape[0] >= batch_size:\n",
    "#             print(\"Warning: Batch size is not greater than sparse soap size.\\nThis may cause errors in the predict_f function which assumes the inducing points to be fewer than the data points.\")\n",
    "#         if settings.my_priority == \"efficiency\":\n",
    "#             gpr_model = gpflow.models.SVGP( kernel=kernel, likelihood=gpflow.likelihoods.Gaussian(),  inducing_variable=sparse_train_sps)\n",
    "#             gpr_model.likelihood.variance.assign(obs_noise)\n",
    "#             gpflow.set_trainable(gpr_model.q_mu, False)\n",
    "#             gpflow.set_trainable(gpr_model.q_sqrt, False)\n",
    "#         else:\n",
    "#             gpr_model = gpflow.models.SGPR(data=(train_sps_j_i, train_ens_j_i), kernel=kernel, noise_variance=obs_noise, inducing_variable=sparse_train_sps)\n",
    "#     else:\n",
    "#         if settings.my_priority == \"efficiency\":\n",
    "#             # it seems I cannot use  noise_variance=obs_noise for this which makes it not GAP...\n",
    "#             gpr_model = gpflow.models.VGP( data=(train_sps_j_i, train_ens_j_i), kernel=kernel, likelihood=gpflow.likelihoods.Gaussian())\n",
    "#         else:\n",
    "#             gpr_model = gpflow.models.GPR( data=(train_sps_j_i, train_ens_j_i), kernel=kernel, noise_variance=obs_noise)\n",
    "#     # --------------------------------------------\n",
    "\n",
    "\n",
    "#     print_frequency = max(settings.min_print_frequency, int(settings.n_epochs/10))\n",
    "\n",
    "#     if settings.my_priority == \"efficiency\":\n",
    "#         hyperparam_history.append([(0, np.exp(var.numpy() )) for var in gpr_model.trainable_variables])  \n",
    "#         gpr_objective = gpr_model.training_loss_closure(batch_iterator,  compile=True)\n",
    "#         for j in range(ci_niter(settings.n_epochs)):\n",
    "#             if not j % print_frequency:\n",
    "#                 print(\"Epoch {}\".format(j))\n",
    "#             optimizer.minimize(gpr_objective, var_list=gpr_model.trainable_variables)\n",
    "#             mse_history.append((j+1, gpr_model.elbo(data=(train_sps, train_ens))))\n",
    "#             hyperparam_history.append([(j+1, np.exp(var.numpy()) ) for var in gpr_model.trainable_variables]) \n",
    "#         #optimizer.minimize(gpr_model.training_loss, gpr_model.trainable_variables, options=dict(maxiter=settings.n_epochs))\n",
    "\n",
    "#     elif settings.my_priority == \"consistency\":\n",
    "\n",
    "#         hyperparam_history.append([(0, var.numpy()) for var in gpr_model.trainable_parameters])  \n",
    "#         for j in range(settings.n_epochs):\n",
    "#             if not j % print_frequency:\n",
    "#                 print(\"Epoch {}\".format(j))\n",
    "#                 #print(\" \".join([\"{} = {:.2e} \".format(var.name, np.exp(var.numpy())) for var in trainable_variables]))\n",
    "\n",
    "#             mse_ens_j = 0\n",
    "#             for i, (train_sps_j_i, train_ens_j_i) in enumerate(islice(batches, iterations_per_epoch)):\n",
    "#                 if not settings.use_forces: #and not settings.sparse_gpflow :\n",
    "#                     gpr_model.data[0].assign(train_sps_j_i)\n",
    "#                     gpr_model.data[1].assign(train_ens_j_i)        \n",
    "#                     mse_ens_j_i = train_hyperparams_without_forces_tf(gpr_model, valid_sps_j, valid_ens_j)\n",
    "#                     print(\"valid_ens[:3] = {}\".format( valid_ens_j[:3].numpy().flatten()) )\n",
    "#     #                 print(mse_ens_j_i.numpy(), valid_ens_j[:3].numpy().flatten(), train_ens_j_i[:3].numpy().flatten()  )\n",
    "\n",
    "\n",
    "#                 else:\n",
    "#                     print(\"Using older approach (not converted to tf.function yet)\")\n",
    "#                     with tf.GradientTape() as tape:\n",
    "#                         with tf.GradientTape(watch_accessed_variables=False) as tape_sps:\n",
    "#                             tape_sps.watch(valid_sps_j)\n",
    "#                             if settings.sparse_gpflow:\n",
    "#                                 gpr_model = gpflow.models.SGPR(data=(train_sps_j_i, train_ens_j_i), kernel=kernel, inducing_variable=sparse_train_sps)\n",
    "#         #                         gpflow.set_trainable(gpr_model.inducing_variable, False)\n",
    "#                                 if i < 3:\n",
    "#                                     print_summary(gpr_model)            \n",
    "#                             else:\n",
    "#                                 gpr_model.data[0].assign(train_sps_j_i)\n",
    "#                                 gpr_model.data[1].assign(train_ens_j_i)\n",
    "#                                 #gpr_model = gpflow.models.GPR(data=(train_sps_j_i, train_ens_j_i), kernel=kernel)\n",
    "#                             #gpr_model.likelihood.variance.assign(obs_noise)                \n",
    "#                             predict_ens_j_i = gpr_model.predict_f(valid_sps_j)[0]\n",
    "\n",
    "#             #                 gpr_model = gpflow.models.GPR(data=(sps_j_i, train_ens_j_i), kernel=kernel_gpf)\n",
    "#             #                 gpr_model.likelihood.variance.assign(obs_noise_gpf)\n",
    "#             #                 predict_ens_j_i_gpf = gpr_model.predict_f(valid_sps_j)\n",
    "\n",
    "#                         if settings.use_forces:\n",
    "#                             predict_d_ens_j_i = tape_sps.gradient(predict_ens_j_i, valid_sps_j)\n",
    "#                             # In the following line I needed to include '* n_atoms' after breaking energies into local energies\n",
    "#                             # The reason is that I am effectively breaking the connection between E and F when doing that\n",
    "#                             # F = -dE/dx =/= -dE_local/dx where E_local = E/n_atoms - E_free\n",
    "#                             # When I split energies into local energies I initially calculated -dE_local/dx which is -dE/dx / n_atoms\n",
    "#                             # This fix is prone to breaking the code and is not robust to systems with different structure size\n",
    "#                             # Need to improve this with a better fix\n",
    "#                             predict_frcs_j_i = -1*np.einsum('ijk,ik->ij', valid_dsp_dx_j, predict_d_ens_j_i) * n_atoms\n",
    "#                             mse_j_i = mse_2factor_tf(predict_ens_j_i, valid_ens_j, 1/ens_var,\n",
    "#                                                     predict_frcs_j_i, valid_frcs_j, 1/frcs_var)\n",
    "#                             mse_ens_j_i = mse_tf(predict_ens_j_i, valid_ens_j)\n",
    "#                         else:\n",
    "#                             mse_j_i = mse_tf(predict_ens_j_i, valid_ens_j)\n",
    "#                             mse_ens_j_i = mse_j_i\n",
    "\n",
    "\n",
    "#             #         grads = tape.gradient(mse_j_i, trainable_variables)\n",
    "#             #         optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "#                     grads = tape.gradient(mse_j_i, gpr_model.trainable_variables)\n",
    "#                     # print(gpr_model.trainable_variables[0])#grads[0])\n",
    "#                     optimizer.apply_gradients(zip(grads, gpr_model.trainable_variables))\n",
    "#                     if i < 3:\n",
    "#                         print_summary(gpr_model)\n",
    "\n",
    "#                     if not gpr_model.data[0][0,0].numpy() == train_sps_j_i[0,0].numpy() :\n",
    "#                         print(\"ERRORERRORERRORERRORERRORERRORERROR\")\n",
    "\n",
    "#                 print(\"Adding mse_ens_j_i to mse_ens_j: {} + {} = {} \".format(mse_ens_j_i.numpy(), mse_ens_j , mse_ens_j_i.numpy() + mse_ens_j  ))\n",
    "#                 mse_ens_j += mse_ens_j_i\n",
    "\n",
    "#             mse_ens_j /= iterations_per_epoch\n",
    "#             print(\"Epoch {},  mse = {}\".format(j, mse_ens_j))\n",
    "#             mse_history.append((j+1, mse_ens_j))\n",
    "#             hyperparam_history.append([(j+1, var.numpy()) for var in gpr_model.trainable_parameters])    \n",
    "#     else:\n",
    "#         print(\"{} is not a reconized value for my_priority.\\n Training did not occur.\".format(settings.my_priority))\n",
    "    \n",
    "#     return gpr_model\n",
    "\n",
    "\n",
    "\n",
    "# TimeBeforeWeights = time.time()\n",
    "# train_hyperparams(train_sps, train_ens, sparse_train_sps, kernel=kernel, settings=s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating weights\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                   </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style=\"text-align: right;\">       value</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style=\"text-align: right;\">1           </td></tr>\n",
       "<tr><td>GPR.kernel.degree      </td><td>Parameter</td><td>Identity        </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style=\"text-align: right;\">2           </td></tr>\n",
       "<tr><td>GPR.kernel.offset      </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style=\"text-align: right;\">2.22507e-308</td></tr>\n",
       "<tr><td>GPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style=\"text-align: right;\">0.0001      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting final energies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 03:43:19.595355: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x561ea8b43e70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TimeBeforeWeights = time.time()\n",
    "print(\"Calculating weights\")\n",
    "\n",
    "if s.my_priority == \"efficiency\" and s.sparse_gpflow == True:\n",
    "    gpr_model =gpr_model\n",
    "elif s.my_priority == \"consistency\":\n",
    "    if s.sparse_gpflow:\n",
    "        gpr_model = gpflow.models.SGPR(data=(train_sps, train_ens), kernel=kernel, noise_variance = gpr_model.likelihood.variance, inducing_variable  = sparse_train_sps)\n",
    "    else:\n",
    "        gpr_model = gpflow.models.GPR( data=(train_sps, train_ens), kernel=kernel, noise_variance = gpr_model.likelihood.variance)      \n",
    "\n",
    "print_summary(gpr_model)\n",
    "\n",
    "if s.sparse_gpflow:\n",
    "    if s.prediction_calculation in (\"direct\", \"cholesky\"):\n",
    "        print(\"Alert: {} prediction approach not implemented for sparse model. Using alpha approach instead.\".format(s.prediction_calculation))\n",
    "        trained_weights = gpr_model.posterior().alpha\n",
    "    elif s.prediction_calculation == \"alpha\":\n",
    "        print(\"Attempting to calculate trained weights using alpha method for sparse gpr model.\")\n",
    "        trained_weights = gpr_model.posterior().alpha\n",
    "        print(\"Successfully calculated trained weights using alpha method for sparse gpr model.\")\n",
    "else:\n",
    "    if s.prediction_calculation in (\"direct\", \"cholesky\"):\n",
    "        KNN = gpr_model.kernel(train_sps)\n",
    "        KNN_diag = tf.linalg.diag_part(KNN)\n",
    "        variance_diag = tf.fill(tf.shape(KNN_diag), gpr_model.likelihood.variance)\n",
    "        KNN_plus_variance = tf.linalg.set_diag(KNN, KNN_diag + variance_diag)\n",
    "        if s.prediction_calculation == \"direct\":\n",
    "            KNN_inv =  tf.linalg.inv(KNN_plus_variance)\n",
    "            trained_weights = tf.matmul(KNN_inv, train_ens)\n",
    "        else:\n",
    "            LNN = tf.linalg.cholesky(KNN_plus_variance)\n",
    "            LNN_inv = tf.linalg.inv(LNN)\n",
    "            KNN_inv_from_L = tf.matmul(LNN_inv, LNN_inv,transpose_a=True)\n",
    "            trained_weights = tf.matmul(KNN_inv_from_L, train_ens)\n",
    "    elif s.prediction_calculation == \"alpha\":\n",
    "        print(\"ERROR: alpha not implemented for gpflow GPR. Skipping prediction\")\n",
    "    \n",
    "TimeAfterTraining = time.time()\n",
    "\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape_sps:\n",
    "    tape_sps.watch(test_sps)  \n",
    "    print(\"Predicting final energies\")\n",
    "    if s.prediction_calculation == \"predict_f\":\n",
    "        predict_ens, predict_ens_var = gpr_model.predict_f(test_sps)\n",
    "    else:\n",
    "        if s.sparse_gpflow:\n",
    "            predict_ens = tf.reshape( predict_energies_from_weights_tf(trained_weights, sparse_train_sps, test_sps, degree), [-1,1])\n",
    "        else:\n",
    "            predict_ens = tf.reshape( predict_energies_from_weights_tf(trained_weights,        train_sps, test_sps, degree), [-1,1])\n",
    "\n",
    "test_ens_rescaled = ens_scaler.inverse_transform(test_ens)\n",
    "predict_ens_rescaled = ens_scaler.inverse_transform(predict_ens)\n",
    "if s.prediction_calculation == \"predict_f\":\n",
    "    predict_ens_var_rescaled =  np.array(predict_ens_var * ens_scaler.scale_ **2)\n",
    "    \n",
    "if s.use_forces:\n",
    "    print(\"Predicting final forces\")    \n",
    "    predict_d_ens = tape_sps.gradient(predict_ens, test_sps)\n",
    "    predict_frcs = -1*np.einsum('ijk,ik->ij', test_dsp_dx, predict_d_ens) * n_atoms\n",
    "\n",
    "    test_frcs_rescaled = test_frcs * ens_scaler.scale_\n",
    "    predict_frcs_rescaled = predict_frcs * ens_scaler.scale_\n",
    "\n",
    "TimeAfterPrediction = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time outside of epochs in training cell  : 1.041\n",
      "Prediction time                                   : 0.838\n"
     ]
    }
   ],
   "source": [
    "TrainingCellNonEpochsTraining = TimeBeforeEpoch0 - TimeBeforePreEpoch + TimeAfterTraining - TimeBeforeWeights \n",
    "if s.n_epochs:\n",
    "    TimePerEpoch = (TimeBeforeWeights - TimeBeforeEpoch0)/s.n_epochs\n",
    "else:\n",
    "    TimePerEpoch = \"N/A\"\n",
    "PredictionTime = TimeAfterPrediction - TimeAfterTraining\n",
    "\n",
    "if s.print_timings:\n",
    "    print(\"{:50s}: {:.3f}\".format(\"Training time outside of epochs in training cell\", TrainingCellNonEpochsTraining))\n",
    "    if s.n_epochs:\n",
    "        print(\"{:50s}: {:.3f}\".format( \"Training time per epoch\", TimePerEpoch))\n",
    "    print(\"{:50s}: {:.3f}\".format(\"Prediction time\", PredictionTime) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored the hyperparameters and mse values for plotting under n=1000\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    if 'mse_history_by_n' not in locals():\n",
    "        mse_history_by_n = {}\n",
    "    if 'hyperparam_history_by_n' not in locals():\n",
    "        hyperparam_history_by_n = {}\n",
    "\n",
    "    hyperparam_history_by_n[s.n_structs] = hyperparam_history\n",
    "    mse_history_by_n[s.n_structs] = mse_history\n",
    "\n",
    "    print(\"Stored the hyperparameters and mse values for plotting under n={}\".format(s.n_structs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hyperparam_training = (in_notebook or s.n_epochs > 0)\n",
    "\n",
    "if plot_hyperparam_training:\n",
    "\n",
    "    palette = plt.get_cmap('gist_ncar')#'nipy_spectral')#\"viridis\")\n",
    "    palette_size = palette.N#len(palette.colors)\n",
    "    palette_itr = 0\n",
    "\n",
    "    fig, [[ax00, ax01], [ax10, ax11]] = plt.subplots(nrows=2, ncols = 2, figsize=(16,12))\n",
    "\n",
    "    hyperparam_names = [\"kernel offset\", \"kernel amplitude\", \"observation noise variance\"]\n",
    "\n",
    "    for n in np.sort(list(mse_history_by_n.keys())):\n",
    "        mse_history = mse_history_by_n[n]\n",
    "        hyperparam_history = hyperparam_history_by_n[n]\n",
    "        if not len(hyperparam_history):\n",
    "            continue\n",
    "        color = palette(palette_itr)\n",
    "        palette_itr = (palette_itr + 30) % palette_size\n",
    "        print(\"The title axes are not assigned correctly. Currently fixing.\")\n",
    "\n",
    "\n",
    "        # hyperparameters on axes 00, 01, 10\n",
    "        hyperparams = np.swapaxes(hyperparam_history, 0, 1)\n",
    "\n",
    "        ax00.plot(*zip(*hyperparams[0]), color=color, label=\"{}\".format(n), lw=3)\n",
    "        ax00.plot(*hyperparams[0][-1], \"o\", color=color)\n",
    "        label00 = hyperparam_names[0]\n",
    "        ax00.set_ylabel(\"{}\".format(label00))\n",
    "    #     #ax00.set_yscale('log')\n",
    "    #     annotation00 = ax00.annotate('{:.1f}'.format(amplitudes[-1][1]) , xy=amplitudes[-1], xycoords='data', xytext=(-30,100),\n",
    "    #                                  textcoords='offset points', bbox={'fc':\"1\"}, arrowprops={'fc':'k'}, zorder=2)\n",
    "        ax00.legend()\n",
    "        ax00.ticklabel_format(useOffset=False)\n",
    "\n",
    "        ax01.plot(*zip(*hyperparams[1]), color=color, label=\"{}\".format(n), lw=3)\n",
    "        ax01.plot(*hyperparams[1][-1], \"o\", color=color)\n",
    "        label01 = hyperparam_names[1]\n",
    "        ax01.set_ylabel(\"{}\".format(label01))\n",
    "    #     #ax01.set_yscale('log')\n",
    "    #     annotation01 = ax01.annotate('{:.1f}'.format(lengths[-1][1]) , xy=lengths[-1], xycoords='data', xytext=(100,-30), \n",
    "    #                                  textcoords='offset points', bbox={'fc':\"1\"}, arrowprops={'fc':'k'}, zorder=2)\n",
    "        ax01.legend()\n",
    "        ax01.ticklabel_format(useOffset=False)\n",
    "\n",
    "        ax10.plot(*zip(*hyperparams[-1]), color=color, label=\"{}\".format(n), lw=3)\n",
    "        ax10.plot(*hyperparams[-1][-1], \"o\", color=color)\n",
    "        label10 = hyperparam_names[-1]\n",
    "        ax10.set_ylabel(\"{}\".format(label10))\n",
    "        #ax10.set_yscale('log')\n",
    "    #     annotation01 = ax10.annotate('{:.1e}'.format(noises[-1][1]) , xy=noises[-1], xycoords='data', xytext=(-30,100),\n",
    "    #                                  textcoords='offset points', bbox={'fc':\"1\"}, arrowprops={'fc':'k'}, zorder=2)\n",
    "    #     ax10.legend()\n",
    "        ax10.ticklabel_format(useOffset=False)\n",
    "\n",
    "        if not len(mse_history):\n",
    "            continue\n",
    "\n",
    "        #loss on axis 11\n",
    "        ax11.plot(*zip(*mse_history), color = color, label=\"{}\".format(n), lw=3)\n",
    "        ax11.plot(*mse_history[-1], \"o\", color=color)\n",
    "        #ax11.set_yscale('log')\n",
    "        bottom, top = ax11.get_ylim()\n",
    "        bottom2, top2 = ax11.get_ylim()\n",
    "        ax11.set_ylabel(\"mse\")\n",
    "        ax11.legend()\n",
    "        ax11.ticklabel_format(useOffset=False)\n",
    "\n",
    "        #fig.suptitle(\"{}\".format(s.n_structs))\n",
    "        \n",
    "        if s.make_output_files and not in_notebook:\n",
    "            hyperparameter_results_filename = \"/hyperparameter_training\"\n",
    "            plt.savefig(calculation_results_directory + hyperparameter_results_filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"from_notebook: \",in_notebook)\n",
    "\n",
    "# run_all_cells = False\n",
    "# assert run_all_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our observation noise variance implies our reference error is +/- 0.00074 /atom\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Energy</th>\n",
       "      <th>Global Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.005557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Absolute Error</th>\n",
       "      <td>0.055351</td>\n",
       "      <td>0.031958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.989915</td>\n",
       "      <td>0.995291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Local Energy  Global Energy\n",
       "Root Mean Squared Error      0.010528       0.007370\n",
       "Mean Absolute Error          0.007660       0.005557\n",
       "Max Absolute Error           0.055351       0.031958\n",
       "r                           0.989915       0.995291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x324 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a regroup function\n",
    "test_ens_regrouped = test_ens_rescaled.reshape(-1, len(StructureList[0]))\n",
    "predict_ens_regrouped = predict_ens_rescaled.reshape(-1, len(StructureList[0]))\n",
    "self_energies_regrouped = [[self_energy(atom.symbol, use_librascal_values=True) for atom in StructureList[i]] for i in test_indices]\n",
    "test_global_ens = np.sum(test_ens_regrouped + self_energies_regrouped, axis=1)\n",
    "predict_global_ens = np.sum(predict_ens_regrouped + self_energies_regrouped, axis=1)\n",
    "\n",
    "if s.prediction_calculation == \"predict_f\":\n",
    "    predict_ens_var_regrouped = predict_ens_var_rescaled.reshape(-1, len(StructureList[0]))\n",
    "    predict_global_ens_var = np.sum(predict_ens_var_regrouped, axis=1)\n",
    "    predict_global_ens_std = predict_global_ens_var ** 0.5 \n",
    "    input_std = (gpr_model.likelihood.variance.numpy() * ens_scaler.scale_[0] **2) ** 0.5\n",
    "    print(\"Our observation noise variance implies our reference error is +/- {:.3} /atom\".format( input_std) )\n",
    "else:\n",
    "    predict_global_ens_std = None\n",
    "plot_errors(model_description = \"gpflow model\",\n",
    "            use_local=True,\n",
    "            global_ens=test_global_ens,   predicted_global_ens= predict_global_ens,\n",
    "            local_ens= test_ens_rescaled, predicted_local_ens = predict_ens_rescaled,\n",
    "            color=\"mediumseagreen\", predicted_stdev = None, n_atoms=n_atoms, in_notebook=in_notebook )\n",
    "\n",
    "\n",
    "if s.make_output_files and not in_notebook:\n",
    "#     settings_string = \"\"\n",
    "#     important_settings = [\"nmax\", \"lmax\", \"rcut\", \"n_structs\", \"n_sparse\", \"n_epochs\"]\n",
    "#     for key, value in settings_dict.items():\n",
    "#         if key in important_settings:\n",
    "#             settings_string += \"_\" +str(key) + \"_\" + str(value)\n",
    "\n",
    "    # check if existing, add number to end if it is\n",
    "    energy_results_title = \"/energy_predictions\"#\"energy_results\" + today_string + settings_string\n",
    "    plt.savefig(calculation_results_directory + energy_results_title)    \n",
    "    # plt.savefig(miniGAP_parent_directory + \"results/\" + energy_results_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s.use_forces:\n",
    "    predict_frcs_rescaled\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, figsize=(20,5))\n",
    "    components = [\"x\", \"y\", \"z\"]\n",
    "    force_max = max(np.max(test_frcs_rescaled), np.max(predict_frcs_rescaled)) + np.std(test_frcs_rescaled)/2\n",
    "    force_min = min(np.min(test_frcs_rescaled), np.min(predict_frcs_rescaled)) - np.std(test_frcs_rescaled)/2\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[i].plot([force_min, force_max], [force_min, force_max], \"-\", c=\"k\")\n",
    "        axs[i].plot(test_frcs_rescaled[:,i], test_frcs_rescaled[:,i], \"o\", c=\"k\", ms=4)\n",
    "        axs[i].plot(test_frcs_rescaled[:,i], predict_frcs_rescaled[:,i], \"o\", label=\"custom\", c=\"mediumseagreen\", ms=5, alpha=.5)\n",
    "        #axs[i].legend()\n",
    "        axs[i].set_xlim(force_min, force_max); axs[i].set_ylim(force_min, force_max)\n",
    "\n",
    "        try:\n",
    "            m, b = np.polyfit(test_frcs_rescaled[:,i], predict_frcs_rescaled[:,i], 1)\n",
    "            r2 = np.corrcoef(test_frcs_rescaled[:,i], predict_frcs_rescaled[:,i])[0,1]\n",
    "            print(\"Least-squares regresion for F{}({}) produces the line line m {}+b with m = {:.5f} and b = {:.5f} which has r2 = {:.5f} \".format(components[i],components[i],components[i],m,b, r2))\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "    #plt.savefig(\"../media/librascal_database_local_energy_force_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This closes the log file. Probably not necessary since it is at the end of the script, but it's best practice.\n",
    "if s.make_output_files and not in_notebook:\n",
    "    logger.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When converting notebook to script, this line acts as a delimiter. Everything above it will remain. Everything below it will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will save this notebook as a python script with today's date in the code directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to convert miniGAP_functional.ipynb to a notebook.\n",
      "If this fails, check to be sure this notebook is in fact named miniGAP_functional.ipynb.\n",
      "\n",
      "[NbConvertApp] Converting notebook miniGAP_functional.ipynb to script\n",
      "[NbConvertApp] Writing 61541 bytes to ../code/miniGAP_from_notebook_12_06_2021.py\n"
     ]
    }
   ],
   "source": [
    "current_notebook_filename = \"miniGAP_functional.ipynb\"\n",
    "converted_script_filename = \"../code/miniGAP_from_notebook\" + today_string \n",
    "print(\"Attempting to convert {} to a notebook.\\nIf this fails, check to be sure this notebook is in fact named {}.\\n\".format(current_notebook_filename, current_notebook_filename))\n",
    "!jupyter nbconvert --to script \"{current_notebook_filename}\" --output \"{converted_script_filename}\"\n",
    "!sed -i '/When converting notebook to script, this line acts as a delimiter/,$d' \"{converted_script_filename}.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minigap]",
   "language": "python",
   "name": "conda-env-minigap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
